"""
Contains functions to generate and combine a clustering ensemble.
"""
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.base import clone
# from clustering.utils import reset_estimator, compare_arrays


def generate_ensemble(data, clusterers: dict, attributes: list, tqdm_args=None):
    """
    It generates an ensemble from the data given a set of clusterers (a
    clusterer is an instance of a clustering algorithm with a fixed set of
    parameters).

    Args:
        TODO: update all

        data:
            A numpy array, pandas dataframe, or any other structure supported
            by the clusterers as data input.
        clusterers:
            A dictionary with clusterers specified in this format: { 'k-means
            #1': KMeans(n_clusters=2), ... }
        attributes:
            A list of attributes to save in the final dataframe; for example,
            including "n_clusters" will extract this attribute from the
            estimator and include it in the final dataframe returned.
        affinity_matrix:
            If the clustering algorithm is AgglomerativeClustering (from
            sklearn) and the linkage method is different than ward (which only
            support euclidean distance), the affinity_matrix is given as data
            input to the estimator instead of data.

    Returns:
        A pandas DataFrame with all the partitions generated by the clusterers.
        Columns include the clusterer name/id, the partition, the estimator
        parameters (obtained with the get_params() method) and any other
        attribute specified.
    """
    if tqdm_args is None:
        tqdm_args = {}

    ensemble = []

    for clus_name, clus_obj in tqdm(clusterers.items(), total=len(clusterers), **tqdm_args):
        # get partition
        #
        # for agglomerative clustering both data and affinity_matrix should be
        # given; for ward linkage, data is used, and for the other linkage
        # methods the affinity_matrix is used
        # if (type(clus_obj).__name__ == "AgglomerativeClustering") and (
        #     clus_obj.linkage != "ward"
        # ):
        #     partition = clus_obj.fit_predict(affinity_matrix).astype(float)
        # else:

        # work on a clone of the given estimator
        clus_obj = clone(clus_obj)

        partition = clus_obj.fit_predict(data)  # .astype(float)

        # remove from partition noisy points (for example, if using DBSCAN)
        # partition[partition < 0] = np.nan

        # get number of clusters
        # partition_no_nan = partition[~np.isnan(partition)]
        # n_clusters = np.unique(partition_no_nan).shape[0]
        n_clusters = np.unique(partition).shape[0]

        # stop if n_clusters <= 1
        if n_clusters <= 1:
            clone(clus_obj)
            raise Exception("Partition has only one cluster")
            # continue

        res = pd.Series(
            {
                "clusterer_id": clus_name,
                "clusterer_params": str(clus_obj.get_params()),
                "partition": partition,
            }
        )

        for attr in attributes:
            if attr == "n_clusters" and not hasattr(clus_obj, attr):
                res[attr] = n_clusters
            else:
                res[attr] = getattr(clus_obj, attr)

        ensemble.append(res)

        # for some estimators such as DBSCAN this is needed, because otherwise
        # the estimator saves references of huge data structures not needed in
        # this context
        clone(clus_obj)

    return pd.DataFrame(ensemble).set_index("clusterer_id")
