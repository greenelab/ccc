{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa1ba1b-d517-4a57-8db0-103ab5bd0a0d",
   "metadata": {
    "papermill": {
     "duration": 0.05443,
     "end_time": "2021-09-21T01:08:26.664204",
     "exception": false,
     "start_time": "2021-09-21T01:08:26.609774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944732c-37a0-4af1-b9c1-86c0c2776126",
   "metadata": {
    "papermill": {
     "duration": 0.018505,
     "end_time": "2021-09-21T01:08:26.702179",
     "exception": false,
     "start_time": "2021-09-21T01:08:26.683674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It computes gene enrichment on *all* the clustering results (obtained using some correlation measure) on a dataset.\n",
    "All these settings are specified below under `Settings`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334aeb5-41a5-4331-9c28-34ec8f755e98",
   "metadata": {
    "papermill": {
     "duration": 0.017986,
     "end_time": "2021-09-21T01:08:26.738014",
     "exception": false,
     "start_time": "2021-09-21T01:08:26.720028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modules loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cf869-a063-4731-bb75-acc121975426",
   "metadata": {
    "papermill": {
     "duration": 0.98246,
     "end_time": "2021-09-21T01:08:27.738520",
     "exception": false,
     "start_time": "2021-09-21T01:08:26.756060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from clustermatch import conf\n",
    "from clustermatch.gene_enrich import run_enrich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f26cf2-d399-470f-94c3-e26dd5b4337d",
   "metadata": {
    "papermill": {
     "duration": 0.018302,
     "end_time": "2021-09-21T01:08:27.775660",
     "exception": false,
     "start_time": "2021-09-21T01:08:27.757358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503767f2-9f51-4828-91ff-50be7d5a6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONFIG = conf.RECOUNT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1fa39-d18c-4a87-bfcc-8d302941544d",
   "metadata": {
    "papermill": {
     "duration": 0.023202,
     "end_time": "2021-09-21T01:08:27.816886",
     "exception": false,
     "start_time": "2021-09-21T01:08:27.793684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we do not need to split by method for recount2\n",
    "# CORRELATION_METHOD_NAME = \"pearson_abs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072fd4d-4b6f-4553-bc17-7bc3d737c7fd",
   "metadata": {
    "papermill": {
     "duration": 0.023527,
     "end_time": "2021-09-21T01:08:27.859971",
     "exception": false,
     "start_time": "2021-09-21T01:08:27.836444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENE_SELECTION_STRATEGY = \"var_pc_log2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b75296-746d-4f4a-b33b-2b003ff9802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterProfiler settings\n",
    "ENRICH_FUNCTION = \"enrichGO\"\n",
    "SIMPLIFY_CUTOFF = 0.7\n",
    "GO_ONTOLOGIES = (\"BP\", \"CC\", \"MF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd099196-edbb-4a17-adce-c7079a221057",
   "metadata": {
    "papermill": {
     "duration": 0.018256,
     "end_time": "2021-09-21T01:08:28.146573",
     "exception": false,
     "start_time": "2021-09-21T01:08:28.128317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e5aa2-0428-4f1b-8af7-41fd7f8208bb",
   "metadata": {
    "papermill": {
     "duration": 0.025744,
     "end_time": "2021-09-21T01:08:28.190353",
     "exception": false,
     "start_time": "2021-09-21T01:08:28.164609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = DATASET_CONFIG[\"CLUSTERING_DIR\"]\n",
    "display(INPUT_DIR)\n",
    "assert INPUT_DIR.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28806e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this directory has the input data given to the clustering methods\n",
    "SIMILARITY_MATRICES_DIR = DATASET_CONFIG[\"SIMILARITY_MATRICES_DIR\"]\n",
    "display(SIMILARITY_MATRICES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff043e-9416-486b-ae13-3dcda0e45f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_MATRIX_FILENAME_TEMPLATE = DATASET_CONFIG[\n",
    "    \"SIMILARITY_MATRIX_FILENAME_TEMPLATE\"\n",
    "]\n",
    "display(SIMILARITY_MATRIX_FILENAME_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7489d8-c09f-43a8-b52c-a9049266f734",
   "metadata": {
    "papermill": {
     "duration": 0.025306,
     "end_time": "2021-09-21T01:08:28.234279",
     "exception": false,
     "start_time": "2021-09-21T01:08:28.208973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = DATASET_CONFIG[\"GENE_ENRICHMENT_DIR\"]\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "display(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d3fbd-1090-466c-aa2e-176f7887c4cc",
   "metadata": {
    "papermill": {
     "duration": 0.019217,
     "end_time": "2021-09-21T01:08:28.355017",
     "exception": false,
     "start_time": "2021-09-21T01:08:28.335800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c38ea-9cb9-4e5f-aa1d-32cf420c45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_pattern = re.compile(DATASET_CONFIG[\"CLUSTERING_FILENAME_PATTERN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c5f50-ec5c-46e8-8918-753cbc941c24",
   "metadata": {
    "papermill": {
     "duration": 0.026976,
     "end_time": "2021-09-21T01:08:28.400716",
     "exception": false,
     "start_time": "2021-09-21T01:08:28.373740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get input data files according to Settings\n",
    "input_files = sorted(\n",
    "    [\n",
    "        f\n",
    "        for f in INPUT_DIR.iterdir()\n",
    "        if (m := re.search(filename_pattern, str(f))) is not None\n",
    "        #         and m.group(\"corr_method\") == CORRELATION_METHOD_NAME\n",
    "    ]\n",
    ")\n",
    "display(len(input_files))\n",
    "display(input_files[:5])\n",
    "\n",
    "assert len(input_files) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d215cb-0ac4-4e56-b61e-affb9de440e1",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe280a-507d-4bb1-a643-08bab491d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_cutoff_str = f\"{SIMPLIFY_CUTOFF:.2f}\".replace(\".\", \"\")\n",
    "display(simplified_cutoff_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e2ed7-42bc-446e-98d5-76f31217c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partitions_per_file = pd.read_pickle(input_files[0]).shape[0]\n",
    "display(n_partitions_per_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754836bb-3b1c-4259-882b-07dfa793c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of tasks is the number of input files times number of partitions per file times 3 (BP, CC, MF)\n",
    "n_tasks = len(input_files) * n_partitions_per_file * 3\n",
    "n_tasks = int(n_tasks)\n",
    "display(f\"number of tasks: {n_tasks}\")\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=conf.GENERAL[\"N_JOBS\"]) as executor, tqdm(\n",
    "    total=n_tasks, ncols=100\n",
    ") as pbar:\n",
    "    for clustering_filepath in input_files:\n",
    "        # extract from input clustering filename some sections, such as tissue name, etc\n",
    "        m = re.search(filename_pattern, str(clustering_filepath.name))\n",
    "\n",
    "        #         tissue = m.group(\"tissue\")\n",
    "        #         gene_sel_strategy = m.group(\"gene_sel_strategy\")\n",
    "        corr_method = m.group(\"corr_method\")\n",
    "\n",
    "        # update pbar description\n",
    "        #         pbar.set_description(f\"{tissue}/{gene_sel_strategy}\")\n",
    "        pbar.set_description(f\"{corr_method}\")\n",
    "\n",
    "        # create output filepath template\n",
    "        full_output_filename_template = (\n",
    "            f\"{clustering_filepath.stem}-{ENRICH_FUNCTION}-{{ontology}}_full.pkl\"\n",
    "        )\n",
    "        simplified_output_filename_template = f\"{clustering_filepath.stem}-{ENRICH_FUNCTION}-{{ontology}}_simplified_{simplified_cutoff_str}.pkl\"\n",
    "\n",
    "        # read clustering results\n",
    "        clustering_df = pd.read_pickle(clustering_filepath)\n",
    "\n",
    "        # get partitions' numbers\n",
    "        tmp_partition = clustering_df.iloc[0].partition\n",
    "        n_genes = tmp_partition.shape[0]\n",
    "        n_clusters = np.unique(tmp_partition).shape[0]\n",
    "\n",
    "        # use those sections to read the list of genes from the input data\n",
    "        # file that the clustering algorithm received\n",
    "        similarity_matrix_filename = SIMILARITY_MATRIX_FILENAME_TEMPLATE.format(\n",
    "            #             tissue=tissue,\n",
    "            #             gene_sel_strategy=gene_sel_strategy,\n",
    "            corr_method=corr_method,\n",
    "        )\n",
    "\n",
    "        # get the universe of genes\n",
    "        all_gene_ids = pd.read_pickle(\n",
    "            SIMILARITY_MATRICES_DIR / similarity_matrix_filename\n",
    "        ).index.tolist()\n",
    "        all_gene_ids = np.array([g.split(\".\")[0] for g in all_gene_ids])\n",
    "        assert all_gene_ids.shape[0] == n_genes\n",
    "\n",
    "        # iterate over clustering solutions (partitions) and GO ontologies\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                run_enrich,\n",
    "                all_gene_ids,\n",
    "                cr_idx,\n",
    "                cr.partition,\n",
    "                ENRICH_FUNCTION,\n",
    "                ontology,\n",
    "                SIMPLIFY_CUTOFF,\n",
    "            ): ontology\n",
    "            for cr_idx, cr in clustering_df.sort_values(\"n_clusters\").iterrows()\n",
    "            for ontology in GO_ONTOLOGIES\n",
    "            if not (\n",
    "                (\n",
    "                    OUTPUT_DIR / full_output_filename_template.format(ontology=ontology)\n",
    "                ).exists()\n",
    "                and (\n",
    "                    OUTPUT_DIR\n",
    "                    / simplified_output_filename_template.format(ontology=ontology)\n",
    "                ).exists()\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # FIXME: this n_expected here is horrible\n",
    "        #  I leave it here for now\n",
    "        futures_n_expected = int(len(GO_ONTOLOGIES) * clustering_df.shape[0])\n",
    "\n",
    "        futures_diff = futures_n_expected - len(futures)\n",
    "        if futures_diff > 0:\n",
    "            pbar.update(futures_diff)\n",
    "\n",
    "        if futures_diff == futures_n_expected:\n",
    "            continue\n",
    "\n",
    "        # collect results\n",
    "        results_full = defaultdict(list)\n",
    "        results_simplified = defaultdict(list)\n",
    "\n",
    "        for task in as_completed(futures):\n",
    "            ont = futures[task]\n",
    "            task_results = task.result()\n",
    "\n",
    "            # continue if no enrichment found\n",
    "            if len(task_results) == 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            results_full[ont].append(task_results[0])\n",
    "\n",
    "            if len(task_results) > 1:\n",
    "                results_simplified[ont].append(task_results[1])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        if len(results_full) == 0:\n",
    "            # no significant results, continue\n",
    "            continue\n",
    "            \n",
    "        # merge and serve\n",
    "        pbar.set_description(f\"{corr_method}/saving\")\n",
    "\n",
    "        for ontology in GO_ONTOLOGIES:\n",
    "            # full\n",
    "            results_full_df = pd.concat(\n",
    "                results_full[ontology], ignore_index=True\n",
    "            ).sort_values([\"clustering_n_clusters\", \"p.adjust\"])\n",
    "\n",
    "            results_full_df.to_pickle(\n",
    "                OUTPUT_DIR\n",
    "                / f\"{clustering_filepath.stem}-{ENRICH_FUNCTION}-{ontology}_full.pkl\",\n",
    "            )\n",
    "\n",
    "            # simplified\n",
    "            if len(results_simplified) > 0:\n",
    "                results_simplified_df = pd.concat(\n",
    "                    results_simplified[ontology], ignore_index=True\n",
    "                ).sort_values([\"clustering_n_clusters\", \"p.adjust\"])\n",
    "\n",
    "                results_simplified_df.to_pickle(\n",
    "                    OUTPUT_DIR\n",
    "                    / f\"{clustering_filepath.stem}-{ENRICH_FUNCTION}-{ontology}_simplified_{simplified_cutoff_str}.pkl\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-gathering",
   "metadata": {
    "papermill": {
     "duration": 0.060723,
     "end_time": "2021-03-01T19:56:24.523453",
     "exception": false,
     "start_time": "2021-03-01T19:56:24.462730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18540.654521,
   "end_time": "2021-03-01T19:56:26.867061",
   "environment_variables": {},
   "exception": null,
   "input_path": "05_cluster_analysis/10_00-clustermatch-go_enrichment.ipynb",
   "output_path": "05_cluster_analysis/10_00-clustermatch-go_enrichment.run.ipynb",
   "parameters": {},
   "start_time": "2021-03-01T14:47:26.212540",
   "version": "2.3.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
